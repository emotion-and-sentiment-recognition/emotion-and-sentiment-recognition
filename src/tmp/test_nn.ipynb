{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "326e8c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe482c08b2e24390835b9e447e07b253",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/30.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9b301206c5b4ecab83977cf35b79e13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/459 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e79ed8f73e524baa9f2e8f45a2f624d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/489k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fac97aadfd7843659b5b3da4928eb935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04ae91df677d4febb39cb3014c7a0aa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/531M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e9a642a7ed645baad54b1f28f9fd865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/531M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1322, 0.1521],\n",
      "        [0.1234, 0.2454],\n",
      "        [0.1551, 0.1268],\n",
      "        [0.1105, 0.1753]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "\n",
    "# Przykładowe dane\n",
    "texts = [\n",
    "    \"Jestem bardzo szczęśliwy z dzisiejszego dnia.\",\n",
    "    \"To był okropny tydzień, jestem załamany.\",\n",
    "    \"Czuję się dobrze, choć trochę zmęczony.\",\n",
    "    \"Jestem bardzo zły na to, co się stało.\"\n",
    "]\n",
    "labels = [1, 0, 1, 0]  # 1 = pozytywna emocja, 0 = negatywna\n",
    "\n",
    "# Tokenizer + model\n",
    "model_name = \"dkleczek/bert-base-polish-cased-v1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "bert_model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Tokenizacja\n",
    "tokens = tokenizer(\n",
    "    texts,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=64,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "# Pobranie embeddingów\n",
    "with torch.no_grad():\n",
    "    outputs = bert_model(**tokens)\n",
    "    embeddings = outputs.last_hidden_state  # [batch, seq_len, hidden]\n",
    "\n",
    "# Definicja sieci\n",
    "class EmotionNet(nn.Module):\n",
    "    def __init__(self, hidden_dim=768, num_classes=2):\n",
    "        super(EmotionNet, self).__init__()\n",
    "        self.lstm = nn.LSTM(hidden_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.attn = nn.Sequential(\n",
    "            nn.Linear(hidden_dim*2, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        self.conv = nn.Conv2d(1, 32, kernel_size=(3, hidden_dim*2))\n",
    "        self.fc = nn.Linear(32, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)  # [batch, seq_len, hidden*2]\n",
    "        attn_weights = self.attn(lstm_out)  # [batch, seq_len, 1]\n",
    "        context = torch.sum(attn_weights * lstm_out, dim=1)  # [batch, hidden*2]\n",
    "        conv_input = lstm_out.unsqueeze(1)  # [batch, 1, seq_len, hidden*2]\n",
    "        conv_out = self.conv(conv_input).squeeze(3).max(2)[0]  # [batch, 32]\n",
    "        out = self.fc(conv_out)\n",
    "        return out\n",
    "\n",
    "net = EmotionNet()\n",
    "output = net(embeddings)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f07aacef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionClassifierLSTM(nn.Module):\n",
    "    def __init__(self, hidden_dim=768, num_classes=2):\n",
    "        super(EmotionClassifierLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(hidden_dim, hidden_dim, bidirectional=True, batch_first=True)\n",
    "        self.attn = nn.Sequential(\n",
    "            nn.Linear(hidden_dim*2, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "        self.classifier = nn.Linear(hidden_dim*2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)  # [batch, seq_len, hidden*2]\n",
    "        attn_weights = torch.softmax(self.attn(lstm_out), dim=1)\n",
    "        context = torch.sum(attn_weights * lstm_out, dim=1)  # [batch, hidden*2]\n",
    "        return self.classifier(context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40677a48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
